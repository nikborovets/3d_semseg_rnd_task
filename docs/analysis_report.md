### **Анализ результатов прототипирования и практические аспекты**

В этом разделе представлен детальный анализ результатов, полученных при запуске трех выбранных архитектур на тестовом облаке точек. Также обсуждаются практические трудности, возникшие в ходе работы, и описываются эксперименты с предобработкой данных.

---

#### **1. Практические трудности и выбор вычислительных ресурсов**

Воспроизведение state-of-the-art моделей сопряжено с рядом инженерных вызовов, от сборки зависимостей до подбора подходящего оборудования.

*   **Проблемы с зависимостями и сборкой:**
    Первой серьезной преградой стала сборка библиотеки **Minkowski Engine**. Процесс оказался чувствительным к версиям компилятора, CUDA и PyTorch, что потребовало тщательного подбора совместимых версий и конфигурации окружения.

*   **Выбор вычислительной платформы:**
    1.  **Локальная машина (Apple MacBook, ARM):** Первоначальные попытки запустить код на локальной машине столкнулись с непреодолимыми трудностями из-за несовместимости C++ кода и CUDA-зависимостей `Minkowski Engine` с ARM-архитектурой.
    2.  **Облачные сервисы (Yandex Cloud):** Следующим шагом была аренда серверов в облаке. Хотя CPU-мощности были доступны, стоимость аренды серверов с GPU оказалась слишком высокой для данного проекта.
    3.  **Кластер МФТИ:** Благодаря доступу к HPC-кластеру ФПМИ МФТИ удалось получить значительные вычислительные ресурсы. Однако ключевым ограничением стала видеопамять: несмотря на большое количество GPU (8x RTX 2080 Ti), каждая карта имела всего 11 ГБ VRAM. Так как реализованные модели не поддерживали нативное распараллеливание инференса на несколько GPU, этого объема оказалось недостаточно для обработки плотных облаков точек в максимальном качестве.
    4.  **Выделенные серверы (Selectel):** Финальным и наиболее успешным решением стала аренда выделенных серверов с мощными GPU (NVIDIA A100 с 40 ГБ VRAM), что позволило запустить самые требовательные конфигурации моделей, включая Sonata с Flash Attention, и провести все необходимые эксперименты.

---

#### **2. Эксперименты с предобработкой данных (Downsampling)**

Исходное облако точек со сканера Leica является очень плотным. Для успешной обработки и снижения "доменного разрыва" между данными Leica и датасетами, на которых обучались модели (S3DIS, ScanNet), были проведены эксперименты с даунсэмплингом.

*   **Мотивация:** Анализ показал, что в стандартных бенчмарках плотность точек соответствует вокселю размером 2-5 см. Приведение тестовых данных к схожей плотности — важный шаг для корректной работы моделей.
*   **Методы:**
    *   **Voxel Grid Downsampling:** Пространство делится на воксельную сетку, и все точки внутри каждого вокселя усредняются в одну. Этот метод создает равномерную, но менее плотную сетку точек.
    *   **Grid Downsampling (случайная точка):** В каждом вокселе выбирается одна случайная точка. Это сохраняет локальную структуру, но также снижает плотность.
*   **Параметры:** Эксперименты проводились с размерами вокселя **3 см** и **5 см**. В перспективе также было бы интересно исследовать влияние пересчета нормалей на качество сегментации, но это не вошло в рамки данной работы.

---

### **3. Визуальный анализ результатов сегментации**

Ниже представлен детальный разбор качества сегментации для каждой из трех реализованных архитектур.

#### **Архитектура 1: Sonata (Transformer-based)**

Sonata, как самая современная модель, продемонстрировала наиболее интересные и вариативные результаты в зависимости от конфигурации.

*   **Конфигурация 1: Без даунсэмплинга (1.2M точек)**
    *   **Наблюдения:** Модель с трудом справляется с избыточной плотностью. Пол и стены сегментируются плохо, с заметными квадратными артефактами.
    *   **Сильные стороны:** Распознавание крупных объектов (столы, стулья, шкафы) в целом успешное. Модель даже корректно определила чехол от гитары и кулер как "другую мебель" (`otherfurniture`).
    *   **Слабые стороны:** Тонкие элементы, такие как ножки столов и стульев, определяются очень плохо.

*   **Конфигурация 2: С Flash Attention (Voxel 3 см)**
    *   **Наблюдения:** Значительное улучшение качества. Пол и стены определены почти идеально.
    *   **Сильные стороны:** Большинство шкафов и других крупных предметов мебели распознаны корректно.
    *   **Слабые стороны:** Проблемы с ножками столов и стульев сохраняются. На сиденьях стульев присутствуют артефакты. Кулер и пуфики распознаны удовлетворительно.

*   **Конфигурация 3: Voxel 5 см, Encoder Patch Size 512 (Лучший результат)**
    *   **Наблюдения:** Эта конфигурация показала наилучший баланс. Дверь, которая ранее игнорировалась, теперь четко видна.
    *   **Сильные стороны:** Пол и столешница определены почти идеально. Проблем с ножками столов стало заметно меньше. На сиденьях стульев отсутствуют артефакты. Чехол гитары и пуфики корректно классифицированы как `otherfurniture`.
    *   **Слабые стороны:** Кулер и барабаны имеют смешанную классификацию (`otherfurniture`/`шкаф`), что, однако, является приемлемым результатом.

*   **Конфигурация 4: Grid Downsampling (Voxel 3 см)**
    *   **Наблюдения:** Очень высокий результат, сопоставимый с предыдущим.
    *   **Сильные стороны:** Модель смогла отличить предметы, лежащие на столе, от самой столешницы, что является признаком высокой детализации. Стулья, кресла и шкафы распознаны отлично, без артефактов. Дверь, пол и стены также определены корректно.

<div align="center">
  <img src="../assets/small_sonata_512_003.gif" alt="Sonata Segmentation Result" width="250"/>
</div>

#### **Архитектура 2: Minkowski Engine (MinkUNet34C, Voxel-based)**

MinkUNet показал себя как надежный, но менее точный baseline.

*   **Конфигурация 1: Voxel 2 см**
    *   **Наблюдения:** Пол определен хорошо, но на стенах появились артефакты — участки с рельефом были неверно классифицированы как шторы (`curtain`). При этом, это единственная модель, которая вообще обратила внимание на этот рельеф.
    *   **Сильные стороны:** Столешница и чехол от гитары (`otherfurniture`) определены неплохо. Модель также сделала интересное наблюдение, классифицировав дверцу шкафа как дверь (`door`).
    *   **Слабые стороны:** Пропущено много шкафов (слились со стеной). Ножки столов, барабаны и гитары на заднем плане распознаны плохо.

*   **Конфигурация 2: Voxel 5 см (Неудачная)**
    *   **Наблюдения:** Результат значительно хуже. Пропали артефакты со стен, но вместе с ними пропала и дверь.
    *   **Слабые стороны:** Множество объектов (шкафы, кулер) были классифицированы как стены. Некоторые стулья, столы и пуфики были ошибочно приняты за пол. В целом, эта конфигурация привела к сильной деградации качества.

<div align="center">
<table>
  <tr>
    <td style="text-align: center; padding: 10px;">
      <p><strong>Конфигурация 1 (Voxel 2 см)</strong></p>
      <img src="../assets/small_mink_002.gif" alt="MinkowskiNet Segmentation Result (Voxel 2cm)" width="250"/>
    </td>
    <td style="text-align: center; padding: 10px;">
      <p><strong>Конфигурация 2 (Voxel 5 см)</strong></p>
      <img src="../assets/small_mink_003.gif" alt="MinkowskiNet Segmentation Result (Voxel 5cm)" width="250"/>
    </td>
  </tr>
</table>
</div>

#### **Архитектура 3: KPConv (KPFCNN, Point-based)**

KPConv, как представитель классического point-based подхода, показал смешанные, но интересные результаты.

*   **Общие наблюдения:** Модель продемонстрировала уверенное распознавание объектов с простой геометрией (стулья, столы) и хорошо справилась с большими плоскими поверхностями (пол, стены). Однако, как и другие модели, она столкнулась с доменным разрывом, что проявилось в тенденции классифицировать незнакомые или сложные объекты как `otherfurniture`.
*   **Сильные стороны:** 
    *   Уверенное распознавание мебели для сидения.
    *   Подобно MinkowskiNet, модель заметила рельеф на стенах, классифицировав его как `door` или `otherfurniture`.
*   **Слабые стороны:**
    *   Пол сегментирован корректно на ~70%.
    *   Наблюдается сильная тенденция к "упрощению" сцены: большинство объектов, включая части стен, классифицируются как `otherfurniture`. Это может свидетельствовать о существенном доменном разрыве между обучающими данными и тестовой сценой.
    *   Изменение параметров даунсэмплинга (размер вокселя, метод) практически не повлияло на итоговый результат, который оставался стабильно невысоким.

<div align="center">
  <img src="../assets/small_kp_conv_003_60000.gif" alt="KPConv Segmentation Result" width="250"/>
</div>
