### **Исследование State-of-the-Art методов семантической сегментации 3D облаков точек**

#### **Введение**

Задача семантической сегментации плотных цветных облаков точек, полученных в сложных внутренних средах с помощью сканера Leica BLK360, требует выбора архитектур, способных эффективно обрабатывать большие объемы неструктурированных данных, сохраняя при этом высокую точность и детализацию. Данное исследование направлено на анализ современных (State-of-the-Art, SOTA) подходов, их сравнительную оценку на основе количественных метрик и формирование ранжированного списка наиболее перспективных методов для решения поставленной задачи.

#### **1. Параметры и критерии выбора State-of-the-Art методов**

Для объективной оценки и ранжирования SOTA-архитектур были определены следующие ключевые параметры, продиктованные спецификой задачи:

*   **Точность (Accuracy):** Основной критерий, измеряемый метрикой **mean Intersection-over-Union (mIoU)** на релевантных бенчмарках (S3DIS, ScanNet, ScanNet200). Высокий mIoU свидетельствует о способности модели точно классифицировать точки для широкого спектра семантических классов.
*   **Эффективность по параметрам (Parameter Efficiency):** Количество обучаемых параметров модели. Этот показатель напрямую влияет на требования к памяти GPU, скорость обучения и инференса, а также на склонность модели к переобучению.
*   **Масштабируемость (Scalability):** Способность архитектуры обрабатывать плотные облака точек, состоящие из десятков и сотен миллионов точек, с приемлемыми затратами вычислительных ресурсов.
*   **Способность использовать цветовую информацию (Utilization of Color):** Нативная поддержка и эффективное использование RGB-данных как дополнительного источника признаков.
*   **Воспроизводимость и доступность (Reproducibility & Availability):** Наличие публичной реализации с открытым исходным кодом и предобученными весами для быстрой валидации.
*   **Потенциал для Open-Vocabulary (Open-Vocabulary Potential):** Способность архитектуры к обобщению на новые, невиданные классы, что значительно расширяет практическую применимость.

#### **2. Сравнительный анализ производительности SOTA-методов**

Для количественного сравнения ключевых архитектур была составлена сводная таблица производительности на основных бенчмарках для семантической сегментации внутренних сцен. Данные собраны из актуальных научных публикаций.

**Сводная таблица производительности (mIoU, %)**

| Архитектура                 | Параметры (М) | ScanNet (test) | ScanNet200 (test) | S3DIS (Area 5) | S3DIS (6-fold) | Год  |
| ---------------------------- | ------------- | -------------- | ----------------- | -------------- | -------------- | ---- |
| KPConv (Deformable)          | 14.3          | -              | -                 | 67.1           | 70.6           | 2019 |
| MinkUNet42                   | 37.9          | 73.6           | 25.3              | 65.4           | -              | 2019 |
| **Sonata (Linear Probing)**    | **<0.2**        | - (72.5 val)   | - (29.3 val)      | **72.3**       | 76.5           | 2024 |
| **PTv3**                       | **124.8**       | 77.9           | **37.8**          | 73.4           | 77.7           | 2024 |
| **Sonata (Decoder Fine-tune)** | **16.3**        | - (79.1 val)   | - (33.5 val)      | **74.5**       | **81.5**       | 2024 |

*Примечание: "-" означает, что данные для данного бенчмарка не были указаны в первоисточниках. Для Sonata приведены результаты на validation-сете ScanNet, которые обычно незначительно ниже результатов на test-сете.*

#### **3. Ранжированный список State-of-the-Art подходов**

На основе представленных количественных данных и качественных критериев был сформирован следующий ранжированный список.

---

#### **1. Sonata (с дообучением декодера)**

*   **Краткое описание:**
    Трансформерная архитектура, использующая мощную предобученную на датасете Objaverse модель в качестве энкодера признаков. В данной конфигурации легковесный декодер дообучается под конкретную задачу семантической сегментации.

*   **Обоснование выбора:**
    1.  **Выдающаяся точность и эффективность:** Sonata демонстрирует наилучшую производительность на ключевых бенчмарках, достигая **81.5% mIoU** на S3DIS (6-fold) и **74.5%** на S3DIS (Area 5), превосходя все рассмотренные аналоги. При этом модель содержит всего **16.3М** параметров — почти в 8 раз меньше, чем PTv3, что делает ее исключительно эффективной.
    2.  **Высокая обобщающая способность:** Масштабное самообучение на разнообразных 3D-объектах дает модели робастные признаки, что потенциально снижает доменный разрыв при переносе на данные со сканера Leica.
    3.  **Ключевой потенциал для Open-Vocabulary:** Архитектура нативно спроектирована для работы в мультимодальном режиме, что открывает возможность для сегментации по произвольному текстовому запросу — это стратегическое преимущество для R&D.

---

#### **2. Point Transformer V3 (PTv3)**

*   **Краткое описание:**
    Последнее поколение трансформерных моделей для облаков точек, использующее сериализацию точек для эффективного применения механизма внимания. Является текущим SOTA решением по "грубой силе".

*   **Обоснование выбора:**
    1.  **Максимальная производительность на сложных задачах:** PTv3 является лидером на самом сложном бенчмарке с большим количеством классов — ScanNet200, где он достигает **37.8% mIoU** на тестовой выборке, значительно опережая MinkUNet (25.3%). Его результат на ScanNet (test) в **77.9% mIoU** также является одним из лучших.
    2.  **Моделирование глобального контекста:** Как и все трансформеры, PTv3 эффективно улавливает дальние зависимости в сцене, что важно для семантической целостности.
    3.  **Недостатки:** Высочайшая производительность достигается ценой огромного количества параметров (**124.8М**), что предъявляет серьезные требования к вычислительным ресурсам и может быть избыточным для задачи с меньшим числом классов.

---

#### **3. Minkowski Engine (MinkUNet)**

*   **Краткое описание:**
    Классическая, но все еще крайне актуальная архитектура на основе разреженных сверток. Является золотым стандартом для эффективной обработки больших облаков точек в воксельном представлении.

*   **Обоснование выбора:**
    1.  **Лучший баланс точности и масштабируемости:** MinkUNet остается эталоном для реальных приложений. Он демонстрирует сильный результат в **73.6% mIoU** на тесте ScanNet, но его главное преимущество — способность обрабатывать облака из сотен миллионов точек при умеренном потреблении памяти, что критично для данных с Leica BLK360.
    2.  **Надежный и проверенный Baseline:** Эта архитектура позволяет количественно оценить, какой прирост производительности дают более тяжелые трансформерные модели и какой ценой (в плане вычислительных ресурсов) он достигается.
    3.  **Высокая зрелость и воспроизводимость:** Являясь широко распространенным инструментом, MinkUNet имеет стабильную кодовую базу и множество предобученных моделей, что делает его самым надежным вариантом для быстрого прототипирования и создания базового решения.

---

#### **4. Архитектуры, выбранные для прототипирования**

Для практической проверки и анализа были выбраны три знаковые архитектуры, представляющие различные парадигмы обработки 3D-данных: классический point-based подход (KPConv), эффективный voxel-based метод (MinkUNet) и современный трансформерный подход, использующий transfer learning (SONATA).

**1. KPConv (Kernel Point Convolution)**

KPConv является фундаментальным **point-based** методом, который выполняет свертки непосредственно над точками, минуя стадию вокселизации. Его ключевая идея заключается в использовании набора "ядерных точек" (kernel points) с обучаемыми весами, которые применяются к локальному окружению каждой точки в облаке. Это позволяет избежать потерь информации, связанных с квантованием, и детально улавливать сложную геометрию объектов. Для прототипа был выбран вариант с **деформируемыми свертками (Deformable KPConv)**, который адаптирует форму ядра под локальную геометрию, демонстрируя более высокую точность (**70.6% mIoU** на S3DIS 6-fold) по сравнению с жесткой версией. KPConv служит мощным baseline-решением, представляющим классический подход к задаче.

**2. Minkowski Engine (MinkUNet34)**

MinkUNet представляет собой **voxel-based** архитектуру, построенную на основе **разреженных сверток (sparse convolutions)** из библиотеки Minkowski Engine. В отличие от стандартных 3D CNN, которые обрабатывают весь объем, включая пустое пространство, MinkUNet выполняет вычисления только для непустых вокселей. Это обеспечивает исключительную вычислительную эффективность и масштабируемость, что критически важно для обработки плотных сканов с Leica. Архитектура U-Net позволяет эффективно агрегировать многомасштабные признаки для точной сегментации. MinkUNet42, показавший **73.6% mIoU** на тесте ScanNet, является золотым стандартом по соотношению точности и производительности и служит эталоном эффективности в категории voxel-based методов.

**3. SONATA (Linear Probing)**

SONATA представляет собой современную **трансформерную архитектуру**, использующую мощный энкодер, предобученный в режиме самообучения на масштабном датасете 3D-объектов Objaverse. Для прототипа была выбрана конфигурация **Linear Probing**: тяжеловесный энкодер "замораживается", и обучается только легковесный линейный классификатор поверх извлеченных им признаков. Этот подход позволяет оценить обобщающую способность предобученной модели с минимальными вычислительными затратами. Несмотря на чрезвычайно малое количество обучаемых параметров (<0.2М), метод достигает высокой точности (**72.3% mIoU** на S3DIS Area 5), что демонстрирует огромную мощь и эффективность современных foundation-моделей в задачах transfer learning.


### **Список литературы**

Ниже представлен список научных работ, составивших теоретическую и практическую основу данного исследования. Он включает как основные анализируемые статьи, так и работы, вводящие ключевые SOTA-архитектуры и бенчмарки, на которые ссылаются авторы для количественной оценки производительности.

#### **Основные статьи исследования**

*   [Betsas, T., Georgopoulos, A., Doulamis, A., & Grussenmeyer, P. (2023). "Deep Learning on 3D Semantic Segmentation: A Detailed Review". *Рукопись, предоставленная для анализа.*](https://arxiv.org/abs/2411.02104)
    *(Эта обзорная статья послужила отправной точкой для классификации и понимания таксономии методов 3D-сегментации).*

*   [Wu, X., Jiang, L., Wang, P. S., et al. (2024). "Point Transformer V3: Simpler, Faster, Stronger". In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*.](https://arxiv.org/abs/2312.10035)
    *(Представляет архитектуру PTv3, которая является текущим SOTA-лидером по точности на многих бенчмарках).*

*   [Wu, X., DeTone, D., Frost, D., et al. (2025). "Sonata: Self-Supervised Learning of Reliable Point Representations". *arXiv preprint arXiv:2403.16429*.](https://arxiv.org/abs/2503.16429v1)
    *(Вводит foundation-модель Sonata, обученную в режиме self-supervised, демонстрирующую выдающуюся эффективность и потенциал для open-vocabulary задач).*

*   [Thomas, H., Qi, C. R., Deschaud, J. E., et al. (2019). "KPConv: Flexible and Deformable Convolution for Point Clouds". In *Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)*.](https://arxiv.org/abs/1904.08889)
    *(Описывает фундаментальный point-based метод KPConv, который является широко используемым baseline-решением).*


#### **Статьи-источники для бенчмарков и SOTA-методов**

*   [Choy, C., Gwak, J., & Savarese, S. (2019). "4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks". In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*.](https://arxiv.org/abs/1904.08755)
    *(Вводит Minkowski Engine и архитектуру MinkUNet, которая является золотым стандартом эффективности для voxel-based методов).*

*   [Dai, A., Chang, A. X., Savva, M., et al. (2017). "ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes". In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*.](https://arxiv.org/abs/1702.04405)
    *(Описывает ключевой бенчмарк ScanNet, широко используемый для оценки моделей семантической сегментации внутренних помещений).*

*   [Armeni, I., Sener, O., Zamir, A. R., et al. (2016). "3D Semantic Parsing of Large-Scale Indoor Spaces". In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*.](https://openaccess.thecvf.com/content_cvpr_2016/html/Armeni_3D_Semantic_Parsing_CVPR_2016_paper.html)
    *(Представляет датасет S3DIS, еще один стандартный бенчмарк для семантической сегментации).*